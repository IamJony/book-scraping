#!/bin/bash

# Created by IamJony
# My github: https://github.com/IamJony
# DESCRIPTION: A Bash script to download books using libraries shadows
# Version: 1.0-1

# Shadown Libraries url

anna='https://annas-archive.org/search?q='
pdfdrive='https://es.pdfdrive.com/search?q='

# Set color
#
White='\e[0;37m'
Black='\e[0;30m'        
Green='\e[0;32m'        
Yellow='\e[0;33m'     
Blue='\e[0;34m' 
Red='\e[0;31m'          
Purple='\e[0;35m'     
Cyan='\e[0;36m'       
     
BBlack='\e[1;30m'       # Black
BRed='\e[1;31m'         # Red
BGreen='\e[1;32m'       # Green
BYellow='\e[1;33m'      # Yellow
BBlue='\e[1;34m'        # Blue
BPurple='\e[1;35m'      # Purple
BCyan='\e[1;36m'        # Cyan
BWhite='\e[1;37m'       # White

# Directory
dir="$HOME/.bookScraping"
mkdir $dir/ 2>/dev/null &

# Delete temporary files
rm $dir/.html_anna* 2>/dev/null &
rm $dir/*.{pdf,fb2,doc,epub,rar,zip,djvu,txt} 2>/dev/null

scraping_fast() {
	
	title_book=$(sed -n 's/.*<h3 class="truncate text-xl font-bold">\([^<]*\)<\/h3>.*/\1/p' $dir/.html_anna > $dir/.title_book_anna)
	book_autor=$(sed -n 's/^.*<div class="truncate italic">\([^<]*\)<\/div>.*$/\1/p' $dir/.html_anna > $dir/.book_autor_anna)
	format_book=$(sed -n 's/^.*<div class="truncate text-xs text-gray-500">\([^<]*MB\).*$/\1/p' $dir/.html_anna > $dir/.format_book_anna)
	link_page=$(sed -n 's/^.*<a[^>]*href="\([^"]*\)".*$/\1/p' $dir/.html_anna | sed -n '/md5/p' > $dir/.link_page_anna)
	md5=$(cat $dir/.link_page_anna)

	file1="$dir/.title_book_anna"
	file2="$dir/.book_autor_anna"
	file3="$dir/.format_book_anna"
	file4="$dir/.link_page_anna"

# Counter
line_num=1

	
while true; do

    # Print the first line of the files
    echo "$(sed -n "${line_num}p" "${file1}") | $(sed -n "${line_num}p" "${file2}") | $(sed -n "${line_num}p" "${file3}")"

    # Increment the line number
    line_num=$((line_num+1))
    
    # Check if the end of the file has been reached #1
    if [[ $(sed -n "$=" "${file1}") -lt $line_num ]]; then
        break
    fi
done
	
}


# User
	echo -e $BYellow''
	read -p "Enter the name of the book to search: " input &&
	input=${input// /+}
	curl "$anna""$input" >> $dir/.html_anna
	scraping_fast > $dir/result
	echo -e $White''
	
	
# FZF
export FZF_DEFAULT_OPTS="--bind='ctrl-x:execute(exit 0)+abort'"
	

if [ ! -s $dir/.title_book_anna ]; then
  echo -e $BRed'no se encontraron resultados'
  sleep 2
  clear
  exit 1
fi

# Read the file and save each line to an array
readarray -t LINES < $dir/result

# Check if the file is empty
if [ ${#LINES[@]} -eq 0 ]; then
  echo "No results found."
  exit 1
fi

OPTIONS=()
for i in "${!LINES[@]}"; do
  OPTIONS+=("$i ${LINES[$i]}")
done

# Run FZF and get the user's selection
OPTION=$(printf '%s\n' "${OPTIONS[@]}" | fzf | awk '{print $1}')

# Validate the user's selection
if [[ "$OPTION" =~ ^[0-9]+$ && "$OPTION" -ge 0 && "$OPTION" -lt "${#LINES[@]}" ]]; then
  echo "==========="
  namedocument=$(echo "$OPTION: ${LINES[$OPTION]}" | sed -n 's/^[^:]*: *\(.*[^ ]\) *|[^|]*|.*/\1/p' | sed 's/[^[:alnum:][:space:]]//g')
  echo "Ha seleccionado la opciÃ³n $OPTION: ${LINES[$OPTION]}"
  ANOTHER_FILE_LINE=$(sed -n "$((OPTION+1))p" $dir/.link_page_anna)
  curl https://annas-archive.org$ANOTHER_FILE_LINE | grep -oP '<li>.*?\K(?<=href=")[^"]*(?=")' > $dir/.donwload_link 

# Downloads directory  
dirdownload='~/Documents'
readarray -t urls < $dir/.donwload_link

for url in "${urls[@]}"
do
    filename=$(basename "$url")
    extension=$(echo "$filename" | sed 's/.*\.//')
    if [[ $filename =~ \.(pdf|epub|txt|zip|rar|djvu|fb2|mobi)$ ]]; then
        wget -nc -P "$dir/" "$url"
        if [ $? -eq 0 ]; then
            echo -e $BGreen'Download finished: ~/Documents/'$namedocument'.'$extension''
            mv $dir/*."$extension" ~/Documents/
           cd ~/Documents/ && mv $filename "$namedocument"."$extension"
           
            break
        fi
    fi
done
else
  echo -e $BRed'No option was selected.'
  exit 1

fi
